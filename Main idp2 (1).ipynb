{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "937781c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tumma\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tumma\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tumma\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Found 11879 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "372/372 [==============================] - 57s 152ms/step\n",
      "63/63 [==============================] - 11s 167ms/step\n",
      "372/372 [==============================] - 3007s 8s/step\n",
      "63/63 [==============================] - 527s 8s/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.applications import VGG16\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image dimensions\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Define AlexNet architecture\n",
    "alexnet_model = Sequential([\n",
    "    Conv2D(96, (11, 11), strides=(4, 4), activation='relu', input_shape=(img_width, img_height, 3)),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    Conv2D(256, (5, 5), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    Conv2D(384, (3, 3), activation='relu'),\n",
    "    Conv2D(384, (3, 3), activation='relu'),\n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1000, activation='softmax')  # 1000 classes in ImageNet, adjust for your task\n",
    "])\n",
    "\n",
    "# Load pre-trained weights (if available)\n",
    "# alexnet_model.load_weights('path_to_pretrained_weights.h5')\n",
    "\n",
    "# Load VGG16 pre-trained model\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Define data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "# Set your training and testing directories\n",
    "train_dir = \"C:\\\\Users\\\\tumma\\\\Desktop\\\\skincancerdetection\\\\train\"\n",
    "test_dir = \"C:\\\\Users\\\\tumma\\\\Desktop\\\\skincancerdetection\\\\test\"\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Generate training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # This means our generator will only yield batches of data, no labels\n",
    "    shuffle=False)  # Important to keep the same order as our labels\n",
    "\n",
    "# Generate testing data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,\n",
    "    shuffle=False)\n",
    "\n",
    "# Extract features using AlexNet\n",
    "alexnet_X_train_features = alexnet_model.predict(train_generator, verbose=1)\n",
    "alexnet_X_test_features = alexnet_model.predict(test_generator, verbose=1)\n",
    "\n",
    "# Extract features using VGG16\n",
    "vgg_X_train_features = vgg_model.predict(train_generator, verbose=1)\n",
    "vgg_X_test_features = vgg_model.predict(test_generator, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9559ab8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tumma\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 128)               3339392   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3349761 (12.78 MB)\n",
      "Trainable params: 3349761 (12.78 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\tumma\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tumma\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "372/372 [==============================] - 25s 43ms/step - loss: 0.6220 - accuracy: 0.6843 - val_loss: 0.5152 - val_accuracy: 0.7695\n",
      "Epoch 2/10\n",
      "372/372 [==============================] - 23s 62ms/step - loss: 0.4969 - accuracy: 0.7788 - val_loss: 0.5080 - val_accuracy: 0.7535\n",
      "Epoch 3/10\n",
      "372/372 [==============================] - 23s 62ms/step - loss: 0.4828 - accuracy: 0.7869 - val_loss: 0.4277 - val_accuracy: 0.8400\n",
      "Epoch 4/10\n",
      "372/372 [==============================] - 23s 61ms/step - loss: 0.4411 - accuracy: 0.8145 - val_loss: 0.4439 - val_accuracy: 0.7900\n",
      "Epoch 5/10\n",
      "372/372 [==============================] - 23s 62ms/step - loss: 0.4247 - accuracy: 0.8221 - val_loss: 0.5328 - val_accuracy: 0.7345\n",
      "Epoch 6/10\n",
      "372/372 [==============================] - 24s 64ms/step - loss: 0.4211 - accuracy: 0.8262 - val_loss: 0.3911 - val_accuracy: 0.8735\n",
      "Epoch 7/10\n",
      "372/372 [==============================] - 24s 64ms/step - loss: 0.4105 - accuracy: 0.8313 - val_loss: 0.3755 - val_accuracy: 0.8750\n",
      "Epoch 8/10\n",
      "372/372 [==============================] - 24s 65ms/step - loss: 0.3996 - accuracy: 0.8381 - val_loss: 0.4268 - val_accuracy: 0.8075\n",
      "Epoch 9/10\n",
      "372/372 [==============================] - 24s 65ms/step - loss: 0.3858 - accuracy: 0.8443 - val_loss: 0.4255 - val_accuracy: 0.7925\n",
      "Epoch 10/10\n",
      "372/372 [==============================] - 24s 65ms/step - loss: 0.3843 - accuracy: 0.8413 - val_loss: 0.3644 - val_accuracy: 0.8550\n",
      "63/63 [==============================] - 1s 20ms/step - loss: 0.3644 - accuracy: 0.8550\n",
      "Test accuracy: 0.8550000190734863\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Concatenate\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Concatenate the features from AlexNet and VGG16\n",
    "concatenated_X_train_features = Concatenate()([Flatten()(alexnet_X_train_features), Flatten()(vgg_X_train_features)])\n",
    "concatenated_X_test_features = Concatenate()([Flatten()(alexnet_X_test_features), Flatten()(vgg_X_test_features)])\n",
    "\n",
    "# Get the actual class labels for training and testing data\n",
    "y_train = train_generator.classes\n",
    "y_test = test_generator.classes\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(concatenated_X_train_features.shape[1],)),  \n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Assuming binary classification, adjust as needed\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',  # Assuming binary classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(concatenated_X_train_features, y_train, epochs=10, batch_size=32,\n",
    "                    validation_data=(concatenated_X_test_features, y_test), callbacks=[early_stop])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(concatenated_X_test_features, y_test)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a817adc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd0088d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 183ms/step\n",
      "1/1 [==============================] - 1s 533ms/step\n",
      "1/1 [==============================] - 0s 127ms/step\n",
      "Predicted class: Benign\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Define the function to preprocess the image\n",
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to match batch size\n",
    "    img_array /= 255.  # Normalize pixel values\n",
    "    return img_array\n",
    "\n",
    "# Define the function to predict the class of the image\n",
    "def predict_image_class(img_path):\n",
    "    preprocessed_img = preprocess_image(img_path)\n",
    "    # Extract features using both AlexNet and VGG16\n",
    "    alexnet_features = alexnet_model.predict(preprocessed_img)\n",
    "    vgg_features = vgg_model.predict(preprocessed_img)\n",
    "    # Flatten the feature maps\n",
    "    alexnet_flattened_features = np.ravel(alexnet_features)\n",
    "    vgg_flattened_features = np.ravel(vgg_features)\n",
    "    # Concatenate the flattened features\n",
    "    concatenated_features = np.concatenate([alexnet_flattened_features, vgg_flattened_features])\n",
    "    # Make prediction using the concatenated features\n",
    "    prediction = model.predict(np.expand_dims(concatenated_features, axis=0))\n",
    "    # Interpret predictions\n",
    "    if prediction > 0.5:\n",
    "        return \"Malignant\"\n",
    "    else:\n",
    "        return \"Benign\"\n",
    "\n",
    "# Test the function on an example image\n",
    "test_image_path = \"C:\\\\Users\\\\tumma\\\\Desktop\\\\skincancerdetection\\\\test\\\\Benign\\\\6315.jpg\"  # Provide the path to your test image\n",
    "predicted_class = predict_image_class(test_image_path)\n",
    "print(\"Predicted class:\", predicted_class)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8701b86e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
